---
title: "Surrogate to Poincaré inequalities on manifolds for structured dimension reduction in nonlinear feature spaces"
collection: publications
category: preprints
permalink: /publication/2026-02-01-surrogate-structured-nonlinear-features
excerpt: 'High-dimensional approximation, Poincaré inequality, collective dimension reduction, structured dimension reduction, nonlinear feature learning, deviation inequalities.'
date: 2026-02-01
venue: "arXiv"
slidesurl: #'https://alexandre-pasco.github.io/files/publications/2026-02-01-surrogate-structurd-nonlinear-features/slides.pdf'
paperurl: 'https://arxiv.org/abs/2602.01143'
bibtexurl: 'https://alexandre-pasco.github.io/files/publications/2026-02-01-surrogate-structurd-nonlinear-features/citation.bib'
citation: 'Pasco, A. and Nouy, A. (2025). Surrogate to Poincaré inequalities on manifolds for structured dimension reduction in nonlinear feature spaces. Preprint. doi:10.48550/arXiv.2602.01143'
---


## Abstract
This paper is concerned with the approximation of continuously differentiable functions with high-dimensional input by a composition of two functions: a feature map that extracts few features from the input space, and a profile function that approximates the target function taking the features as its low-dimensional input.
We focus on the construction of structured nonlinear feature maps, that extract features on separate groups of variables, using a recently introduced gradient-based method that leverages Poincaré inequalities on nonlinear manifolds.
This method consists in minimizing a non-convex loss functional, which can be a challenging task, especially for small training samples.
We first investigate a collective setting, in which we construct a feature map suitable to a parametrized family of high-dimensional functions.
In this setting we introduce a new quadratic surrogate to the non-convex loss function and show an upper bound on the latter.
We then investigate a grouped setting, in which we construct separate feature maps for separate groups of inputs, and we show that this setting is almost equivalent to multiple collective settings, one for each group of variables.